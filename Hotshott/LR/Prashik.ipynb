{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5a18919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/lplmwndn2l1cw5q526nm0rlh0000gn/T/ipykernel_32663/3172104342.py:46: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  self.bias -= self.alpha * db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on the training set: nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class LinearRegressionScratch:\n",
    "    def __init__(self, alpha=0.01, n_iterations=1000, lambda_ridge=0.0, lambda_lasso=0.0):\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.n_iterations = n_iterations  # Number of iterations for gradient descent\n",
    "        self.lambda_ridge = lambda_ridge  # Regularization strength for Ridge\n",
    "        self.lambda_lasso = lambda_lasso  # Regularization strength for Lasso\n",
    "        self.weights = None  # Model weights\n",
    "        self.bias = None  # Model bias\n",
    "\n",
    "    def _initialize_weights(self, n_features):\n",
    "        # Initialize weights and bias to zero\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "    def _compute_cost(self, X, y):\n",
    "        # Number of samples\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Predictions using current weights and bias\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        \n",
    "        # Compute the cost with Ridge and Lasso penalties\n",
    "        cost = (1 / (2 * n_samples)) * np.sum((y_pred - y) ** 2)\n",
    "        ridge_penalty = (self.lambda_ridge / (2 * n_samples)) * np.sum(self.weights ** 2)\n",
    "        lasso_penalty = (self.lambda_lasso / (2 * n_samples)) * np.sum(np.abs(self.weights))\n",
    "        \n",
    "        return cost + ridge_penalty + lasso_penalty\n",
    "\n",
    "    def _gradient_descent(self, X, y):\n",
    "        # Number of samples\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Compute the gradient for weights and bias\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "        # Apply Ridge and Lasso penalties\n",
    "        dw += (self.lambda_ridge / n_samples) * self.weights + (self.lambda_lasso / n_samples) * np.sign(self.weights)\n",
    "\n",
    "        # Update weights and bias\n",
    "        self.weights -= self.alpha * dw\n",
    "        self.bias -= self.alpha * db\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Number of features\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self._initialize_weights(n_features)\n",
    "        \n",
    "        # Gradient descent for a number of iterations\n",
    "        for _ in range(self.n_iterations):\n",
    "            self._gradient_descent(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Return the predicted values\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Separate features and target in training data\n",
    "X_train = train_data.drop('score',axis=1)  # Features\n",
    "y_train = train_data['score']  # Target\n",
    "\n",
    "# Test data features\n",
    "X_test = test_data.values\n",
    "\n",
    "# Initialize and train the model with Ridge and Lasso regularization\n",
    "model = LinearRegressionScratch(alpha=0.01, n_iterations=1000, lambda_ridge=0.1, lambda_lasso=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to a DataFrame and save to CSV\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predicted_Target'])\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Optional: Calculate the Mean Squared Error (MSE) on the training set\n",
    "train_predictions = model.predict(X_train)\n",
    "mse = np.mean((train_predictions - y_train) ** 2)\n",
    "print(f'Mean Squared Error (MSE) on the training set: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "accf1fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34988, 65)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a39b95fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34988, 66)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048c5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
